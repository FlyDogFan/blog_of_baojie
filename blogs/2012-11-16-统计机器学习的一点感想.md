统计机器学习的一点感想
---
    
> Categories: 流水帐, 语义网  
> Time: 2012-11-16  
> Original url: <http://baojie.org/blog/2012/11/16/statistical-machine-leaning/>
    
最近看了两篇文章，有些感想。Noam Chomsky on Where Artificial Intelligence Went Wrong, 2012-11-01, The AtlanticPeter Norvig: On Chomsky and the Two Cultures of Statistical LearningChomsky和Norvig都是人工智能界的泰斗级学者，他们各执一辞，论述自己对统计机器学习的看法。两篇文章看完，都让人深受启发。争论的大意是，Chomsky认为统计方法虽然在工程上有效，但是太“肤浅”，没有展示问题的本质。Norvig说，可是这玩意就是有效、有效、有效，这里是例子、例子、例子。其实两个人说得都没错。这里我做个类比：一天24小时，一年365天多一点，这个是统计学习。古人从海量的数据里得到了这些规律，用来指导生活，简单有效。伟大的天文学家如第谷，编制了大量的星表来表述这些统计发现，在一定范围内是准确的。为什么一天24小时，一年365天多一点？深入理解，要太阳系模型和万有引力定律。这个靠统计学习是学不出来的。开普勒从第谷积累的海量数据里总结出三定律，不但能解释地球的自转和公转，还能解释其他行星的运行规律。牛顿进一步解释开普勒三定律，其实用万有引力定律都可以解释。如果这场争论是放在16世纪天文学，Norvig大体上侧重于“一天24小时，一年365天多一点”的重要性，而Chomsky侧重于发现万有引力定律的重要性。     其实都没错。统计方法有统计方法的价值和适用范围。在这个范围内是有效的。但它不是万灵药。机器学习、数据挖掘、自然语言处理，这十年来统计方法流行。但把这种流行上升为信仰就不可取了。“大数据”hype里有人认为，什么算法都不重要，只要数据足够多，就能发现需要的规律——我觉得这就近乎宗教迷信了。比如现在我们有DBPedia知识库。如果没有Wikipedia，单纯用机器来统计学习Web上所有的文档，我怀疑能不能产生出DBPedia这样质量的知识库（尽管DBPedia自己的质量也依然不令人满意）。关键不在数据的多少，而在高质量数据有多少。相比其他Web文档，Wikipedia就是高质量数据。而目前，高质量数据的产生，还是要依赖人。统计学习，是起一个重要但辅助的作用。又比如问答系统，如Siri和Watson，都依赖于大量人工写作的模板、数据源和知识库。在此基础上，统计机器学习等诸多方法集成，方能完成自然语言理解、知识查找这样复杂的任务。为什么把Siri扩展到中文或其他语言难？因为那些模板、数据源和知识库都没有英文世界全。各种统计机器学习的方法，对中文和英文都是存在的，但他们不能离开高质量数据（知识）而工作。期间若干步骤本身，也是统计方法、知识方法和算法方法的集成，如知识库的提取本身，如解析器（Parser）的设计，如问题的分类，如文档的细粒度分析，如备选答案的排序。统计方法里可以套知识方法，知识方法里可以套统计方法。锤子用来砸钉子，扳手用来拧螺丝，非要说哪个好哪个不好，就是迷信。我们工程师最要不得的就是迷信。锤子和扳手都是好东西，想把活干好，最好都备上。     
    