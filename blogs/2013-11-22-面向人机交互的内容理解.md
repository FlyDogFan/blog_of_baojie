面向人机交互的内容理解
---
    
> Categories: Uncategorized, 语义网  
> Time: 2013-11-22  
> Original url: <http://baojie.org/blog/2013/11/22/hci-centric-nlp/>
    
看到 Chris Manning和Oren Etzioni等就是否“Texts are knowledge”的论战。我的观点是：

> 基于NLP的结构化是太难了，但是文档的结构分析相对容易，篇章段落句子本身就是人的智能分割过的。仅仅把这些结构变成可查询的东西就会有很大的应用


这里收集了以前关注这个主题的一些微博，按时间逆序。很抱歉没有时间来组织，部分内容在以前一些帖子里也引用过了。

我们在Memect就在实践这些原则，希望在工程的可实现性和商业的可持续性间找到一个平衡点。不管最后的探索结果如何，这个探索的过程是非常有趣的。

也请参前文

- 2013-07-31  论集体记忆
- 2013-02-10 HCI Class笔记

传统的知识工程方法常被隔壁学科鄙视。确实，如果按Cyc那种方法，投入产出比很差。其实这个领域，如果转换思路，从以机器为中心的处理方法转到以人为中心的处理方法，让数据的表示和交换都面向人来优化，未必不能走出一条新路。DB， NLP， IR， HCI这些学科都有丰富的营养可以吸取 2013-09月15日 01:17

不是页面深层语义的结构化，是文档本身结构的可查询化。//@Siegfried围脖:你太乐观了，非结构化到结构化这个天堑，不是一个编辑器就能解决的，否则早解决了。//@西瓜大丸子汤: 通过结构化“语义”数据，构造对终端用户友好的用户界面。 2013-08-16, 23:46

这个例子是最典型的，通过结构化“语义”数据，构造对终端用户友好的用户界面。第一是改进了的编辑界面能进一步扩大用户群。二是每一个维基百科页面都将是完整的，可以查询的结构化知识，远远超过dbpedia。一旦部署到维基百科，这样的基础高质量数据对自然语言理解，检索等领域有难以估计的深远影响 2013-08月16日 17:14 

http://t.cn/zQuXyzX http://t.cn/zQuXyz6 Mediwiki最近的VisualEditor和Parsoid项目都用到了RDFa。一旦部署到Wikipedia（等升级到MW 1.22）, 那是语义数据运动的极大胜利啊。 2013-08月16日 16:59 

在Web3.0上为什么强调结构化数据的价值？简单如hashtag，复杂如分类规则，可以加强人对数据的可发现性，更好的利用人的智能而不仅仅是机器智能。这对数据的索引带来全新的挑战，不是传统搜索引擎式索引可以满足的。第一，要有对人友好而不是对机器友好的索引。二，人的需求不可完全预知，所以需要懒索引

对第一点，要强调索引的目的是为了更好帮助用户建立生物记忆和外在记忆的关系，而不仅是机器查找的速度。对第二点，索引不可能事先全部建好，而必须在和用户的交互中on-demand, just-in-time地更新。所以说Web3.0的核心是一场HCI的革命，结构化数据是这场革命的催化剂 2013-08月12日 11:17

总结对语义网和HCI的讨论：语义网是一门工程，不是一门科学；是一门面向人的工程，不是一门面向机器的工程；语义网的创新突破点可能在HCI，不是在知识提取或者知识表现与推理。 2013-08月03日 08:32

David对语义网应用的定义：A Semantic Web application is one whose schema is expected to change. 语义网应用就是数据模式会改变的应用 2013-08月03日 08:23

David的很多话也是别人讲过的(jim, frank)：语义网的创新是在Web，不是Semantic。结构化数据服务于终端用户，核心不是能不能的问题，是能不能搞得更容易的问题。所有的元素其实都在那，就看好的工程师怎么把它们整合在一起。 2013-08月03日 08:11

这个HCI革命的关键，是界面适应用户复杂多样的需求和认知限制的矛盾。原则也都是语义网界说烂了几条原则：数据与应用的分离；数据的自描述性；数据的弱／无模式性；数据的可演进性。在工具上，利用有这些属性的数据来允许用户各行其是：用他们熟悉的工作模式，用他们熟悉的组织方式，不强迫改变什么 2013-08月03日 08:17

church的那篇文章，讲统计学派过去20年把容易摘的果子都摘了，剩下的都是硬骨头。还有没有低果子可摘呢? 我看还有，就是 Clay Shirky说的认知剩余，现在用了大概1%不到。等待一个hci的革命，来改变剩下的99%。2013-08-02, 15:12     

David Karger原来也在Csail的五楼。他是语义网界少有的一直贯彻从人机交互的角度来考察语义数据的人。exhibit, google refine都是在他影响下产生出来的。和他接触后，才改变了我只从机器的角度去理解人工智能的想法。是人产生了几乎全部有价值的数据。真正的AI的革命都是伴随着HCI的革命的 2013-08-02, 14:20

为什么说人机交互是解决AI问题的核心？机器学习这些方法，就好比金融系统，把财富(知识)转移。社会要富裕，光靠金融不行，要工业农业，把财富创造出来。智能系统也一样，不管是训练样本还是知识规则，都要靠人来产生。加快这个产生的效率，靠得是hci。web就是hci的革命，有了这类革命才能解放认知剩余 2013-08-02, 15:05

语义网的研究人员其实可以从电子表格的发展中学到很多。结构化数据的根本在人，在结构发生的地方。通过结构便利数据的表示方式的变化和用户对数据的理解。查询，推理都是附加需求。 2013-06-17, 07:46

结构化数据的编辑器里，真正普及的，我能想到的只有电子表格spreadsheet。其他树型结构，图结构，似乎都还没有普及的编辑界面。 2013-06月17日 07:14 

用户界面不应该被预先设计的schema限制，不管这个schema是在数据库中还是在应用软件中。spreadsheet和faceted browser都是在schema和用户多样化界面需求上折衷的好例子，虽然还只是一小步。 2013-06-07, 02:46

基于语义维基的应用就是这样一类应用的雏形。应用逻辑和数据建模这两者本身都数据化了，代码本身即可查询，可扩展，并且支持和知识库的集成 //@vicwutaojun:认同，其实这也是一种解放，将技术使用的门槛降低到普通人都可以发起一些新的变革 2013-06-07, 13:32

语义网的核心价值之一就是设计不可预期的应用。一种活的数据，一种活的应用。 2013-06-07, 02:47

Google Glass之类的工具提供了一个激活的契机。并行的数据展示，低的数据归档和检索摩擦力。和以前一样，hci的革命带来数据组织的革命，再导致人工智能的革命//@西瓜大丸子汤:移动设备是数据流动的工具。但数据并仅仅要流动，还要沉淀和组织。个人数据管理还是个待激活的市场 2013-06-09, 05:47

不论是文档web还是social web，都只是数据的冰山一角。90%的数据隐藏在可搜索界面之外。而这些数据才是最有商业价值的数据。不仅仅针对企业，对个人数据也一样 //@西瓜大丸子汤:俺的看法和梅姐不一样。intelligence at interface需要数据组织的革命，不仅是个界面问题 2013-05-08, 10:57

> @cnBeta 【梅耶尔：未来大部分的搜索创新都将在用户界面和语音搜索中产生】据外媒报道，雅虎现任CEO梅耶尔在参加Wired Business Conference中透露，日前，雅虎正在全力开发搜索功能，而他们将开发的重点定在了搜索的前端表现上。梅耶尔解释道，未来大部分的搜索创新… http://t.cn/zTHlXbw


集体记忆需要的知识表现方法，为了适应普通用户，需要容忍不精确性。但不精确性并不是通过概率的方法。知识表现的目的并不是推理，而是促进知识在时间和空间两个维度的低摩擦流动。摩擦的主要阻力在用户界面而不是知识提取。 2013-04月07日 10:39

底层精确语义确实需要NLP。但是这一块能实用化还有一定距离。非自然语言处理的结构化还是有空间的，也有可能工业化 2013-04月07日 10:27

Pinterest作为碎片组织的工具，和传统的tagging有区别。它提供了川流不息的数据碰撞和分化的渠道，而传统的tagging只能作为静态的属性。数据流（在界面上是瀑布流的方式）提高了数据的可发现性(findability)，从而可能带来各种不可预期serendipity。数据的组织和低摩擦流动：这也是语义网要追求的目标 2013-02月24日 06:49 

Faceted Browser走出了一小步。Google Glass和其他的可穿戴计算机将走出一大步。帮助用户发现甚至他们自己都不知道怎么表达的需要，启发用户，允许用户将工作记忆从recall变成recognition，这会是极其惊人的革命//@西瓜大丸子汤: Web3.0的一个重要特点将是辅助用户降低工作记忆(working memory)负担 2013-02月10日 18:36 

我也没有好办法。要解决这个可能得开个公司专业搞。我觉得应可能的比例是60%统计+20%本体与NLP+20%启发式HCI。 2012-11-27 16:40:46

一个词总结Web 3.0：做减法。这是逆Web 2.0的趋势而动。Web在未来10年会渗透到70亿人中现在还不活跃于Web2.0那80%的人，延续Web2.0 的思路是不成的。怎么做减法，各种技术，包括新型用户界面，各种新型数据录用、采集方式，数据理解，用户理解，语义分析，高质量（结构化）数据，push技术，等等。 2012-09-03 12:11:50 

我总觉得解决这个问题可能是靠HCI而非NLP或semantic web //@潘越_:对于以文本为基础的wiki这种信息产生的方式，众包容易成功。知识库的建设怕是比较难。自然语言里的冗余信息某种程度上保障了众包的质量。知识库建设的质量保证？好像还无章可循。 2012-08-27 00:52:30     
    