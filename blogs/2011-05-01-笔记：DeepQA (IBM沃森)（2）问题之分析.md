笔记：DeepQA (IBM沃森)（2）问题之分析
---
    
> Categories: 笔记, 语义网  
> Time: 2011-05-01  
> Original url: <http://baojie.org/blog/2011/05/01/deep-qa-2/>
    
David A. Ferrucci et al,Building Watson: An Overview of the DeepQA Project. AI Magazine 31(3): 59-79 (2010).==DeepQA方式==一句话总结：a massively parallel probabilistic evidence-based architecture多种方法的集成：we use more than 100 different techniques for analyzing natural language, identifying sources, ﬁnding and generating hypotheses, ﬁnding and scoring evidence, and merging and ranking hypotheses.四项基本原则：massive parallelism, many experts, pervasive conﬁdence estimation, and integration of shallow and deep knowledge.==指标==第一要能答尽可能多的问题Percentage Attempted第二要能答对precision因为知识有限，答的多，有些没有把握的也答，就更容易出错。把两者做坐标画一个曲线，是一个下降的线。目标就是把这个线提高。沃森的各个版本渐次做到这一点（Fig 9）人类参赛者一般回到20%-60%问题，正确率70%-100%。特别牛X的回答50%-80%，正确率80%-100%。     所以系统设计，要计算对答案的置信度，如果太低，就不答。==基准==设计沃森前，团队用现成的Q/A系统跑了跑 Jeopardy。 PIQUANT对5%的问题有47%的正确率，总的正确率是13%。OpenEphyra答对了45%——利用Web搜索。更有趣的是，他们比较了纯文本搜索（text search）和结构化数据（structured data）查询。文本搜索的曲线是上升的，但很快稳定在30%，表示文本搜索可以覆盖更多的问题，但是比较盲目（不知道答案是否“好”）。结构化查询对某些已知类型问题有效，但对这之外的，比搜索还差。==分析问题==Q/A的第一步是分析问题Q(uestion)。每个问题有一个类（category），比如历史、科学、政治，这是已知的。问题可以分解为子问题，子问题可以是并列的关系，或者嵌套的关系。这需要对问题句子做自然语言结构分析。每个问题有一个关键词被称为“domain”（域），比如“这个皇帝死于北京的那年一共有三个不同国号的皇帝在北京登基”的域就是“皇帝”。域也称lexical answer type (LAT)。分布很分散，2万个问题就有2500个LAT。因为LAT太多，针对每个域做特别的建模就不可行了。问题还要做关系检测（Relation Detection），也就是动词，比如“和北京相邻的省”中关系是“相邻”。     
    